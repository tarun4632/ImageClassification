{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ML Summer School Project 1 \n",
    "\n",
    "## Deep Learning with MNIST dataset and Dog Cat classification dataset"
   ],
   "id": "d5c32fadeff2cef8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing Required libraries - ",
   "id": "bdc37713c78d0784"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T01:44:08.686068Z",
     "start_time": "2024-06-20T01:44:04.347981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch                                                                # importing pytorch \n",
    "from torch import nn                                                        # importing the nn class from the torch \n",
    "import numpy as np                                                          # numpy is the mathematical library for python \n",
    "import pandas as pd                                                         # for data preprocessing\n",
    "import matplotlib.pyplot as plt                                             # Data Visualisation Library for python \n",
    "# import seaborn as sns                                                       # datavisualisation lib\n",
    "import torchvision.transforms as transforms                                 # contains various transforms to apply to the dataset \n",
    "from torchvision.datasets import MNIST                                      # importing the Mnist dataset from the torchvision library\n",
    "import sklearn                                                              # ML assistance \n",
    "from sklearn.model_selection import train_test_split                        # function for spliting the data into train, val and test sets\n",
    "from torchvision.transforms import ToTensor                                 # function used for converting the images into tensors \n",
    "from torch.utils.data import DataLoader                                     # to make the dataset an python iterable "
   ],
   "id": "d26270c98fd5e9cb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading data from the `torchvision.datasets.MNIST` -",
   "id": "37aa369955208aee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:35.778098Z",
     "start_time": "2024-06-19T08:46:35.578757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_val_data = MNIST(\n",
    "    root = \"data\",                                                          # this is the root directory in which we want our dataset\n",
    "    train=True,                                                             # this signifies that this is the training data \n",
    "    transform=ToTensor(),                                                   # this is to transform the data into the tensor form\n",
    "    target_transform=None,                                                  # takes in the target and transforms it\n",
    "    download=False\n",
    ")\n",
    "\n",
    "test_data = MNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    "    download=False\n",
    ")"
   ],
   "id": "c3f24e95e8e619cd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:35.787528Z",
     "start_time": "2024-06-19T08:46:35.779286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "ce234d9c2601fc85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:35.830049Z",
     "start_time": "2024-06-19T08:46:35.789993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "train_size = int(0.8 * len(train_val_data))\n",
    "val_size = len(train_val_data) - train_size\n",
    "train_data, val_data = random_split(train_val_data, [train_size, val_size])\n"
   ],
   "id": "de989c179f84689b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analysing the data",
   "id": "f8add8cb698ff115"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:35.836127Z",
     "start_time": "2024-06-19T08:46:35.831918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analysing the Label Values from the data \n",
    "\n",
    "class_names = train_val_data.classes"
   ],
   "id": "bdbf13474739349c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:36.068033Z",
     "start_time": "2024-06-19T08:46:36.063089Z"
    }
   },
   "cell_type": "code",
   "source": "test_data.class_to_idx",
   "id": "ac5a0c9a2512308c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': 0,\n",
       " '1 - one': 1,\n",
       " '2 - two': 2,\n",
       " '3 - three': 3,\n",
       " '4 - four': 4,\n",
       " '5 - five': 5,\n",
       " '6 - six': 6,\n",
       " '7 - seven': 7,\n",
       " '8 - eight': 8,\n",
       " '9 - nine': 9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualisation of the data",
   "id": "d79669d7d058c893"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:38.676521Z",
     "start_time": "2024-06-19T08:46:38.485012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "def show_image(image):\n",
    "    image_np = image.numpy()\n",
    "    \n",
    "    image_np = image_np.transpose((1,2,0))\n",
    "    \n",
    "    plt.imshow(image_np.squeeze(), cmap = \"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "image, label = train_val_data[0]                            # the train dataset contains the image and the labels \n",
    "show_image(image) "
   ],
   "id": "3d7db8df0c7e14b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### visualizing multiple images \n",
    "\n",
    "Function to print multiple images from the train dataset with the labels as there headings \n",
    "- basically making a figure of figsize = (r*c, r*c)\n",
    "- then running a loop over the training set for r*c times \n",
    "- taking a random index every time\n",
    "- adding a subplot of size (r,c) at the i th position \n",
    "- showing the image there of that random index"
   ],
   "id": "e00dc0aa92bbe207"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:42.856770Z",
     "start_time": "2024-06-19T08:46:40.549301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows, columns = 4,4\n",
    "fig = plt.figure(figsize=(rows*columns, rows*columns))\n",
    "for i in range(1, rows*columns+1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    image, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows,columns,i)\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)\n",
    " "
   ],
   "id": "562299116e70e261",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 16 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T08:46:46.934629Z",
     "start_time": "2024-06-19T08:46:42.859391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting the number of images for each of the class \n",
    "from collections import Counter\n",
    "\n",
    "train_classes = [label for i , label in train_data]\n",
    "frequency = dict(Counter(train_classes))\n",
    "\n",
    "# plt.hist(frequency)"
   ],
   "id": "aeb743755cb05f5c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "34abd1b6e2d2a558"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating DataLoaders for our data- \n",
    "\n",
    "- dataloaders are used to basically make the mini batches for the training of the data\n",
    "- it creates out dataset a python iterable"
   ],
   "id": "2cb3b1435b9ba0ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.792981Z",
     "start_time": "2024-06-18T20:28:04.787992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(train_data, 64, True)\n",
    "val_dataloader = DataLoader(val_data, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, shuffle=True)"
   ],
   "id": "8b8bcc4d4157fb19",
   "outputs": [],
   "execution_count": 272
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.813572Z",
     "start_time": "2024-06-18T20:28:04.796833Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(train_dataloader))",
   "id": "d0181189ca15af40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([3, 4, 4, 8, 5, 6, 7, 4, 1, 4, 9, 9, 6, 1, 0, 3, 2, 6, 3, 3, 7, 0, 8, 2,\n",
       "         5, 1, 2, 1, 4, 0, 6, 6, 8, 5, 5, 5, 8, 5, 0, 3, 5, 6, 0, 9, 7, 4, 4, 1,\n",
       "         4, 8, 2, 7, 9, 4, 5, 1, 9, 5, 1, 1, 3, 2, 6, 7])]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.826636Z",
     "start_time": "2024-06-18T20:28:04.815224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"no. of train features - {train_features.size()}\")\n",
    "print(f\"no. of train labels - {train_labels.size()}\")"
   ],
   "id": "7d37fc96ed7b79cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of train features - torch.Size([64, 1, 28, 28])\n",
      "no. of train labels - torch.Size([64])\n"
     ]
    }
   ],
   "execution_count": 274
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model 1 : Fully Connected Model-\n",
    "    - model using only fully connected layers and no convolutional layers\n",
    "    - basically making a normal neural network to test its accuracy"
   ],
   "id": "4e319549cbb460c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.833162Z",
     "start_time": "2024-06-18T20:28:04.827712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTv0(nn.Module):                                    # inhereting the parent class nn.module for our models, will do this in every model for pytorch\n",
    "    def __init__(self, input_shape:int, \n",
    "                 output_shape:int):\n",
    "        \"\"\"\n",
    "        initializes FashionMNIST model \n",
    "        \n",
    "        args:\n",
    "            input_shape (int): shape of input images\n",
    "            output_shape (int): shape of output images\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(in_features=input_shape, out_features=512, bias=True)                           # total number of parameters in this layer = (784+1)*(512) = 401920\n",
    "        self.layer2 = nn.Linear(in_features=512, out_features=256, bias=True)                                   # total number of parameters in this layer = (512+1)*256 = 131328\n",
    "        self.layer3 = nn.Linear(in_features=256, out_features=output_shape, bias=True)                          # total number of parameters in this layer = (256+1)*10 = 2570\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        return self.layer3(self.relu(self.layer2(self.relu(self.layer1(self.flatten(x))))))"
   ],
   "id": "b21d8282ce5c3d5e",
   "outputs": [],
   "execution_count": 275
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.843715Z",
     "start_time": "2024-06-18T20:28:04.834406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_0 = MNISTv0(input_shape=28*28, output_shape=len(class_names))\n",
    "model_0"
   ],
   "id": "2a09ec5fadec51c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTv0(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layer1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (layer2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (layer3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 276
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.848811Z",
     "start_time": "2024-06-18T20:28:04.844895Z"
    }
   },
   "cell_type": "code",
   "source": "sum(p.numel() for p in model_0.parameters() if p.requires_grad)                                # total numebr of parameters for this model = 401920+131328+2570 = 535818\n",
   "id": "25d29cab1469fb44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535818"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 277
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.854440Z",
     "start_time": "2024-06-18T20:28:04.849988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "input_shape = 784\n",
    "summary(model_0, input_size=(1, input_shape))"
   ],
   "id": "521447736d7b02e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                  [-1, 256]         131,328\n",
      "              ReLU-5                  [-1, 256]               0\n",
      "            Linear-6                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 2.04\n",
      "Estimated Total Size (MB): 2.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing the optimizer and the loss function for the model training",
   "id": "a987202579cf799d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.860079Z",
     "start_time": "2024-06-18T20:28:04.857107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr = 0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "id": "acf5d9807553fbc8",
   "outputs": [],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.863846Z",
     "start_time": "2024-06-18T20:28:04.861014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    return correct / len(y_true) * 100"
   ],
   "id": "3978484517be36a0",
   "outputs": [],
   "execution_count": 280
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Building Training and testing loops and functionsa",
   "id": "cf45319ad31be899"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.868920Z",
     "start_time": "2024-06-18T20:28:04.864645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device):\n",
    "    \n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        train_loss += loss.item()  # Convert to scalar and accumulate\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))  # Go from logits -> pred labels\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    return train_loss, train_acc"
   ],
   "id": "1fe33e437aebad14",
   "outputs": [],
   "execution_count": 281
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.876414Z",
     "start_time": "2024-06-18T20:28:04.870287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def val_step(data_loader: torch.utils.data.DataLoader,\n",
    "             model: torch.nn.Module,\n",
    "             loss_fn: torch.nn.Module,\n",
    "             accuracy_fn,\n",
    "             device: torch.device):\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss, val_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():  # Disable gradient computation\n",
    "        for X, y in data_loader:\n",
    "            val_pred = model(X)  # Perform a forward pass through the model\n",
    "            \n",
    "            # Calculate loss and accuracy\n",
    "            val_loss += loss_fn(val_pred, y).item()\n",
    "            val_acc += accuracy_fn(y_true=y,\n",
    "                                   y_pred=val_pred.argmax(dim=1))  # Go from logits -> pred labels\n",
    "    \n",
    "    val_loss /= len(data_loader)\n",
    "    val_acc /= len(data_loader)\n",
    "    \n",
    "    return val_loss, val_acc"
   ],
   "id": "78b9b3cb94959f70",
   "outputs": [],
   "execution_count": 282
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:28:04.883100Z",
     "start_time": "2024-06-18T20:28:04.877555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.inference_mode():  # Disable gradient computation\n",
    "        for X, y in data_loader:\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y) # Convert to scalar and accumulate\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=test_pred.argmax(dim=1))  # Go from logits -> pred labels\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "    return test_loss, test_acc"
   ],
   "id": "68201b4d7d1f4b1f",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training our first fully connected network",
   "id": "b761eaaa40397926"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:29:18.382131Z",
     "start_time": "2024-06-18T20:28:04.883940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_accuracy = train_step(model=model_0, data_loader=train_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, optimizer=optimizer, device=device)\n",
    "    \n",
    "    val_loss, val_accuracy = val_step(data_loader=val_dataloader, model=model_0, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Save the model if it has the best validation loss so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model_0.state_dict(), 'best_model_fcc1.pth')\n",
    "\n"
   ],
   "id": "dccbd24db26887a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:07<01:10,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.8085, Train Accuracy: 59.91%, Val Loss: 0.9270, Val Accuracy: 81.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [00:14<00:57,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6218, Train Accuracy: 84.60%, Val Loss: 0.4729, Val Accuracy: 87.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [00:21<00:50,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.4194, Train Accuracy: 88.45%, Val Loss: 0.3826, Val Accuracy: 89.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [00:28<00:41,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.3576, Train Accuracy: 89.95%, Val Loss: 0.3438, Val Accuracy: 90.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [00:34<00:34,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.3239, Train Accuracy: 90.86%, Val Loss: 0.3196, Val Accuracy: 90.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [00:42<00:28,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.2999, Train Accuracy: 91.48%, Val Loss: 0.2991, Val Accuracy: 91.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [00:50<00:21,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.2806, Train Accuracy: 91.96%, Val Loss: 0.2849, Val Accuracy: 91.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [00:57<00:14,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.2644, Train Accuracy: 92.44%, Val Loss: 0.2731, Val Accuracy: 92.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [01:05<00:07,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.2495, Train Accuracy: 92.91%, Val Loss: 0.2575, Val Accuracy: 92.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [01:13<00:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.2361, Train Accuracy: 93.31%, Val Loss: 0.2475, Val Accuracy: 93.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:29:18.386024Z",
     "start_time": "2024-06-18T20:29:18.383143Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b50411f1844ee6ba",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:29:20.907477Z",
     "start_time": "2024-06-18T20:29:18.387133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# for testing \n",
    "# Load the best model for testing\n",
    "model_0.load_state_dict(torch.load('best_model_fcc1.pth'))\n",
    "test_loss, test_accuracy = test_step(data_loader=test_dataloader, model=model_0, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "id": "39302459700fcf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2291, Test Accuracy: 93.47%\n"
     ]
    }
   ],
   "execution_count": 285
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## using K Fold validation",
   "id": "1cde876428e51d42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:29:20.912568Z",
     "start_time": "2024-06-18T20:29:20.909686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "num_epochs = 5\n"
   ],
   "id": "b74a76927487b597",
   "outputs": [],
   "execution_count": 286
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:32:53.314181Z",
     "start_time": "2024-06-18T20:29:20.914011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define empty lists to store losses and accuracies\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "\n",
    "# Training loop for k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_val_data)):\n",
    "    print(f'Fold {fold + 1}/{k_folds}')\n",
    "    \n",
    "    # Initialize model, optimizer, criterion for each fold\n",
    "    model = MNISTv0(input_shape= 784, output_shape=10)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    fold_training_losses = []\n",
    "    fold_validation_losses = []\n",
    "\n",
    "\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_val_data, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset=train_val_data, sampler=val_sampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Reset model parameters for each epoch\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss, train_accuracy = train_step(model=model, data_loader=train_loader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, optimizer=optimizer, device=device)\n",
    "        val_loss, val_accuracy = val_step(data_loader=val_loader, model=model, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "        \n",
    "        fold_training_losses.append(train_loss)\n",
    "        fold_validation_losses.append(val_loss)\n",
    " \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    training_losses.append(fold_training_losses)\n",
    "    validation_losses.append(fold_validation_losses)\n",
    "\n",
    "\n",
    "print('K-fold cross-validation completed.')\n"
   ],
   "id": "c2a31dd00e565ec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/5, Train Loss: 1.7765, Train Accuracy: 62.74%, Val Loss: 0.9104, Val Accuracy: 79.90%\n",
      "Epoch 2/5, Train Loss: 0.6179, Train Accuracy: 84.59%, Val Loss: 0.4653, Val Accuracy: 87.28%\n",
      "Epoch 3/5, Train Loss: 0.4188, Train Accuracy: 88.49%, Val Loss: 0.3780, Val Accuracy: 89.45%\n",
      "Epoch 4/5, Train Loss: 0.3585, Train Accuracy: 89.87%, Val Loss: 0.3384, Val Accuracy: 90.12%\n",
      "Epoch 5/5, Train Loss: 0.3261, Train Accuracy: 90.73%, Val Loss: 0.3153, Val Accuracy: 90.87%\n",
      "Fold 2/5\n",
      "Epoch 1/5, Train Loss: 1.7649, Train Accuracy: 61.13%, Val Loss: 0.8933, Val Accuracy: 80.30%\n",
      "Epoch 2/5, Train Loss: 0.6113, Train Accuracy: 84.59%, Val Loss: 0.4725, Val Accuracy: 87.38%\n",
      "Epoch 3/5, Train Loss: 0.4197, Train Accuracy: 88.43%, Val Loss: 0.3879, Val Accuracy: 89.36%\n",
      "Epoch 4/5, Train Loss: 0.3595, Train Accuracy: 89.75%, Val Loss: 0.3484, Val Accuracy: 90.55%\n",
      "Epoch 5/5, Train Loss: 0.3259, Train Accuracy: 90.70%, Val Loss: 0.3222, Val Accuracy: 91.18%\n",
      "Fold 3/5\n",
      "Epoch 1/5, Train Loss: 1.8173, Train Accuracy: 60.17%, Val Loss: 0.9488, Val Accuracy: 80.60%\n",
      "Epoch 2/5, Train Loss: 0.6265, Train Accuracy: 84.50%, Val Loss: 0.4751, Val Accuracy: 86.96%\n",
      "Epoch 3/5, Train Loss: 0.4188, Train Accuracy: 88.45%, Val Loss: 0.3820, Val Accuracy: 89.47%\n",
      "Epoch 4/5, Train Loss: 0.3593, Train Accuracy: 89.80%, Val Loss: 0.3430, Val Accuracy: 90.42%\n",
      "Epoch 5/5, Train Loss: 0.3264, Train Accuracy: 90.72%, Val Loss: 0.3167, Val Accuracy: 91.16%\n",
      "Fold 4/5\n",
      "Epoch 1/5, Train Loss: 1.8537, Train Accuracy: 57.75%, Val Loss: 0.9900, Val Accuracy: 79.12%\n",
      "Epoch 2/5, Train Loss: 0.6479, Train Accuracy: 83.88%, Val Loss: 0.4925, Val Accuracy: 86.56%\n",
      "Epoch 3/5, Train Loss: 0.4295, Train Accuracy: 88.21%, Val Loss: 0.3969, Val Accuracy: 88.62%\n",
      "Epoch 4/5, Train Loss: 0.3656, Train Accuracy: 89.72%, Val Loss: 0.3545, Val Accuracy: 89.69%\n",
      "Epoch 5/5, Train Loss: 0.3314, Train Accuracy: 90.53%, Val Loss: 0.3276, Val Accuracy: 90.44%\n",
      "Fold 5/5\n",
      "Epoch 1/5, Train Loss: 1.8021, Train Accuracy: 59.72%, Val Loss: 0.9395, Val Accuracy: 79.68%\n",
      "Epoch 2/5, Train Loss: 0.6279, Train Accuracy: 84.17%, Val Loss: 0.4789, Val Accuracy: 86.94%\n",
      "Epoch 3/5, Train Loss: 0.4215, Train Accuracy: 88.47%, Val Loss: 0.3828, Val Accuracy: 89.12%\n",
      "Epoch 4/5, Train Loss: 0.3611, Train Accuracy: 90.00%, Val Loss: 0.3437, Val Accuracy: 90.03%\n",
      "Epoch 5/5, Train Loss: 0.3292, Train Accuracy: 90.61%, Val Loss: 0.3194, Val Accuracy: 90.74%\n",
      "K-fold cross-validation completed.\n"
     ]
    }
   ],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:32:53.317935Z",
     "start_time": "2024-06-18T20:32:53.315422Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4bc65455693d0dbf",
   "outputs": [],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:32:55.908826Z",
     "start_time": "2024-06-18T20:32:53.319331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = test_step(data_loader=test_dataloader, model=model, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "id": "c53b8336b977e2bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3036, Test Accuracy: 91.29%\n"
     ]
    }
   ],
   "execution_count": 288
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model 2 : Comvolutional Neural Network\n",
    "    - model using convo2d layers and fully connected layers\n",
    "    - the conv blocks with the max pooling is used to extract useful features and along with that decrease the number of parameters the fully connected layer has to process resulting in lesser computational usage "
   ],
   "id": "3e5990586845e511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:32:55.930339Z",
     "start_time": "2024-06-18T20:32:55.912638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTv1(nn.Module):\n",
    "    def __init__(self, output_shape: int):\n",
    "        super(MNISTv1, self).__init__()\n",
    "        \"\"\"\n",
    "        Initializes the MNIST model\n",
    "        \n",
    "        Args:\n",
    "            output_shape (int): shape of output (number of classes)\n",
    "        \"\"\"\n",
    "        self.conv_layer_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1, stride=1),  # params = (kernel size +1)*no. of filters = (9+1)*64\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1), # Number of weights=in_channelsout_channelskernel_heightkernel_width\n",
    "                                                                                             # 64*128*3*3 = 73728\n",
    "                                                                                             # params = number of weights + number of bias = 73728 + 128 = 73,856\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        )\n",
    "        self.conv_layer_stack2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1, stride=1), # 128*64*3*3 + 64 = 73,792\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1, stride=1), #64*32*3*3 + 32 = 18,464\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fcc = nn.Sequential(\n",
    "            nn.Linear(in_features=32 * 7 * 7, out_features=128), # params = 3277=1568*128 = 200704+128 = 200832\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64), # params = (128+1)*64 = 8256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=output_shape) # params = (64+1)*10 = 650\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv_layer_stack(x)\n",
    "        x = self.conv_layer_stack2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fcc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model_1 = MNISTv1(output_shape=10)\n",
    "print(model_1)\n",
    "\n",
    "\n"
   ],
   "id": "314d1fbf20436746",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTv1(\n",
      "  (conv_layer_stack): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_layer_stack2): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fcc): Sequential(\n",
      "    (0): Linear(in_features=1568, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 289
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:32:56.029652Z",
     "start_time": "2024-06-18T20:32:55.931619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "input_shape = (1,28,28)\n",
    "summary(model_1, input_size=input_shape)"
   ],
   "id": "bbcce0baf1c8885a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             640\n",
      "              ReLU-2           [-1, 64, 28, 28]               0\n",
      "            Conv2d-3          [-1, 128, 28, 28]          73,856\n",
      "              ReLU-4          [-1, 128, 28, 28]               0\n",
      "         MaxPool2d-5          [-1, 128, 14, 14]               0\n",
      "            Conv2d-6           [-1, 64, 14, 14]          73,792\n",
      "              ReLU-7           [-1, 64, 14, 14]               0\n",
      "            Conv2d-8           [-1, 32, 14, 14]          18,464\n",
      "              ReLU-9           [-1, 32, 14, 14]               0\n",
      "        MaxPool2d-10             [-1, 32, 7, 7]               0\n",
      "          Flatten-11                 [-1, 1568]               0\n",
      "           Linear-12                  [-1, 128]         200,832\n",
      "             ReLU-13                  [-1, 128]               0\n",
      "           Linear-14                   [-1, 64]           8,256\n",
      "             ReLU-15                   [-1, 64]               0\n",
      "           Linear-16                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 376,490\n",
      "Trainable params: 376,490\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.80\n",
      "Params size (MB): 1.44\n",
      "Estimated Total Size (MB): 4.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 290
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:32:56.035088Z",
     "start_time": "2024-06-18T20:32:56.030840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(model_1.parameters(), lr = 0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "id": "42fb0f8ca5e2b733",
   "outputs": [],
   "execution_count": 291
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T21:12:43.243720Z",
     "start_time": "2024-06-18T20:32:56.036504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_accuracy = train_step(model=model_1, data_loader=train_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, optimizer=optimizer, device=device)\n",
    "    \n",
    "    val_loss, val_accuracy = val_step(data_loader=val_dataloader, model=model_1, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Save the model if it has the best validation loss so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model_0.state_dict(), 'best_model_cnn1.pth')\n",
    "\n"
   ],
   "id": "79b7c6b726101fa3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [03:41<33:15, 221.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.3020, Train Accuracy: 10.78%, Val Loss: 2.3010, Val Accuracy: 10.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [07:53<31:54, 239.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.2983, Train Accuracy: 11.37%, Val Loss: 2.2954, Val Accuracy: 10.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [11:38<27:10, 232.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.7436, Train Accuracy: 40.98%, Val Loss: 0.5311, Val Accuracy: 83.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [15:38<23:33, 235.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.3657, Train Accuracy: 88.38%, Val Loss: 0.2697, Val Accuracy: 91.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [19:31<19:34, 234.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.2168, Train Accuracy: 93.18%, Val Loss: 0.1628, Val Accuracy: 94.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [23:41<15:59, 239.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.1502, Train Accuracy: 95.31%, Val Loss: 0.1267, Val Accuracy: 96.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [27:16<11:35, 231.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.1149, Train Accuracy: 96.40%, Val Loss: 0.1045, Val Accuracy: 96.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [31:20<07:51, 235.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0928, Train Accuracy: 97.11%, Val Loss: 0.0932, Val Accuracy: 97.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [35:21<03:57, 237.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0803, Train Accuracy: 97.51%, Val Loss: 0.0831, Val Accuracy: 97.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [39:47<00:00, 238.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0702, Train Accuracy: 97.78%, Val Loss: 0.0700, Val Accuracy: 97.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 292
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T21:13:09.209916Z",
     "start_time": "2024-06-18T21:12:43.295069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# for testing \n",
    "# Load the best model for testing\n",
    "model_0.load_state_dict(torch.load('best_model_cnn1.pth'))\n",
    "test_loss, test_accuracy = test_step(data_loader=test_dataloader, model=model_1, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "id": "f95b219673a29592",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0589, Test Accuracy: 98.12%\n"
     ]
    }
   ],
   "execution_count": 293
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## using K fold Validation",
   "id": "4cdbcf00dbbaecf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T21:13:09.228697Z",
     "start_time": "2024-06-18T21:13:09.213411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "num_epochs = 5\n"
   ],
   "id": "4676e07586152ca1",
   "outputs": [],
   "execution_count": 294
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:39:33.620687Z",
     "start_time": "2024-06-18T21:13:09.284701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define empty lists to store losses and accuracies\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "\n",
    "# Training loop for k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_val_data)):\n",
    "    print(f'Fold {fold + 1}/{k_folds}')\n",
    "    \n",
    "    # Initialize model, optimizer, criterion for each fold\n",
    "    model1 = MNISTv1(output_shape=10)\n",
    "    optimizer = torch.optim.SGD(model1.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    fold_training_losses = []\n",
    "    fold_validation_losses = []\n",
    "\n",
    "\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_val_data, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset=train_val_data, sampler=val_sampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Reset model parameters for each epoch\n",
    "        model1.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss, train_accuracy = train_step(model=model1, data_loader=train_loader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, optimizer=optimizer, device=device)\n",
    "        val_loss, val_accuracy = val_step(data_loader=val_loader, model=model1, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "        \n",
    "        fold_training_losses.append(train_loss)\n",
    "        fold_validation_losses.append(val_loss)\n",
    " \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    training_losses.append(fold_training_losses)\n",
    "    validation_losses.append(fold_validation_losses)\n",
    "\n",
    "\n",
    "print('K-fold cross-validation completed.')\n"
   ],
   "id": "3e0a5336bcd35500",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/5, Train Loss: 2.3016, Train Accuracy: 10.70%, Val Loss: 2.2997, Val Accuracy: 11.29%\n",
      "Epoch 2/5, Train Loss: 2.2978, Train Accuracy: 11.22%, Val Loss: 2.2929, Val Accuracy: 11.29%\n",
      "Epoch 3/5, Train Loss: 1.8534, Train Accuracy: 37.57%, Val Loss: 0.5588, Val Accuracy: 82.26%\n",
      "Epoch 4/5, Train Loss: 0.3874, Train Accuracy: 87.48%, Val Loss: 0.2944, Val Accuracy: 90.27%\n",
      "Epoch 5/5, Train Loss: 0.2282, Train Accuracy: 92.77%, Val Loss: 0.1844, Val Accuracy: 94.08%\n",
      "Fold 2/5\n",
      "Epoch 1/5, Train Loss: 2.3028, Train Accuracy: 10.68%, Val Loss: 2.3000, Val Accuracy: 11.31%\n",
      "Epoch 2/5, Train Loss: 2.2967, Train Accuracy: 11.22%, Val Loss: 2.2883, Val Accuracy: 11.31%\n",
      "Epoch 3/5, Train Loss: 1.4053, Train Accuracy: 53.20%, Val Loss: 0.4429, Val Accuracy: 84.12%\n",
      "Epoch 4/5, Train Loss: 0.3070, Train Accuracy: 90.24%, Val Loss: 0.2253, Val Accuracy: 93.19%\n",
      "Epoch 5/5, Train Loss: 0.1912, Train Accuracy: 93.93%, Val Loss: 0.1634, Val Accuracy: 94.88%\n",
      "Fold 3/5\n",
      "Epoch 1/5, Train Loss: 2.3027, Train Accuracy: 10.25%, Val Loss: 2.3000, Val Accuracy: 11.35%\n",
      "Epoch 2/5, Train Loss: 2.2944, Train Accuracy: 12.35%, Val Loss: 2.2801, Val Accuracy: 20.86%\n",
      "Epoch 3/5, Train Loss: 1.1671, Train Accuracy: 63.46%, Val Loss: 0.3455, Val Accuracy: 89.18%\n",
      "Epoch 4/5, Train Loss: 0.2988, Train Accuracy: 90.48%, Val Loss: 0.2459, Val Accuracy: 92.13%\n",
      "Epoch 5/5, Train Loss: 0.1939, Train Accuracy: 93.88%, Val Loss: 0.1617, Val Accuracy: 94.78%\n",
      "Fold 4/5\n",
      "Epoch 1/5, Train Loss: 2.3021, Train Accuracy: 10.81%, Val Loss: 2.3008, Val Accuracy: 10.93%\n",
      "Epoch 2/5, Train Loss: 2.3001, Train Accuracy: 11.31%, Val Loss: 2.2988, Val Accuracy: 10.93%\n",
      "Epoch 3/5, Train Loss: 2.2942, Train Accuracy: 11.31%, Val Loss: 2.2807, Val Accuracy: 10.93%\n",
      "Epoch 4/5, Train Loss: 1.1990, Train Accuracy: 61.15%, Val Loss: 0.3570, Val Accuracy: 88.88%\n",
      "Epoch 5/5, Train Loss: 0.2666, Train Accuracy: 91.50%, Val Loss: 0.1978, Val Accuracy: 93.86%\n",
      "Fold 5/5\n",
      "Epoch 1/5, Train Loss: 2.3027, Train Accuracy: 10.53%, Val Loss: 2.3005, Val Accuracy: 11.32%\n",
      "Epoch 2/5, Train Loss: 2.2964, Train Accuracy: 11.22%, Val Loss: 2.2875, Val Accuracy: 11.32%\n",
      "Epoch 3/5, Train Loss: 1.3763, Train Accuracy: 56.55%, Val Loss: 0.4757, Val Accuracy: 84.00%\n",
      "Epoch 4/5, Train Loss: 0.3200, Train Accuracy: 89.78%, Val Loss: 0.2334, Val Accuracy: 92.81%\n",
      "Epoch 5/5, Train Loss: 0.2023, Train Accuracy: 93.68%, Val Loss: 0.1592, Val Accuracy: 95.24%\n",
      "K-fold cross-validation completed.\n"
     ]
    }
   ],
   "execution_count": 295
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:39:58.504430Z",
     "start_time": "2024-06-19T02:39:33.630684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = test_step(data_loader=test_dataloader, model=model1, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "id": "80d57945bc54922a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1489, Test Accuracy: 95.24%\n"
     ]
    }
   ],
   "execution_count": 296
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model 2 : Fully Convolutional Neural Network\n",
    "    - model using convo2d layers and fully connected layers\n",
    "    - the conv blocks with the max pooling is used to extract useful features and along with that decrease the number of parameters the fully connected layer has to process resulting in lesser computational usage "
   ],
   "id": "ea0798a4b55abcf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T09:44:26.334614Z",
     "start_time": "2024-06-19T09:44:26.317202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class MNISTv2(nn.Module):\n",
    "    def __init__(self, output_shape: int):\n",
    "        super(MNISTv2, self).__init__()\n",
    "        \"\"\"\n",
    "        Initializes the MNIST model\n",
    "        \n",
    "        Args:\n",
    "            output_shape (int): shape of output (number of classes)\n",
    "        \"\"\"\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),               # params = (1*16*3*3) = 144 +16 = 160\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size= 3),             # params = (16*32*3*) = 4608 + 32 = 4640\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))\n",
    "        )\n",
    "        \n",
    "        self.conv_stack2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),              # params = (32*64*3*3) = 18432 + 64 = 18496\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3),              # params = (32*64*3*3) = 18432 + 32 = 18464\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2))\n",
    "        )\n",
    "        self.conv_stack3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3),                # params = 321633=4608 + 16 = 4624\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=output_shape, kernel_size=1),        # params = 161011=160 +10 = 170\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        x = self.conv_stack3(self.conv_stack2(self.conv_stack(x)))\n",
    "        x = nn.Flatten(x.size(0), -1)\n",
    "        return x\n",
    "model_2 = MNISTv2(output_shape=10)\n",
    "model_22 = MNISTv2(output_shape=10)\n",
    "model_2"
   ],
   "id": "eaa617b75b59c239",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTv2(\n",
       "  (conv_stack): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_stack2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_stack3): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:39:58.692336Z",
     "start_time": "2024-06-19T02:39:58.535167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_shape = (1,28,28)\n",
    "summary(model_2, input_size=input_shape)"
   ],
   "id": "4b3dd58231599cde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 26, 26]             160\n",
      "              ReLU-2           [-1, 16, 26, 26]               0\n",
      "            Conv2d-3           [-1, 32, 24, 24]           4,640\n",
      "              ReLU-4           [-1, 32, 24, 24]               0\n",
      "         MaxPool2d-5           [-1, 32, 12, 12]               0\n",
      "            Conv2d-6           [-1, 64, 10, 10]          18,496\n",
      "              ReLU-7           [-1, 64, 10, 10]               0\n",
      "            Conv2d-8             [-1, 32, 8, 8]          18,464\n",
      "              ReLU-9             [-1, 32, 8, 8]               0\n",
      "        MaxPool2d-10             [-1, 32, 4, 4]               0\n",
      "           Conv2d-11             [-1, 16, 2, 2]           4,624\n",
      "             ReLU-12             [-1, 16, 2, 2]               0\n",
      "           Conv2d-13             [-1, 10, 2, 2]             170\n",
      "             ReLU-14             [-1, 10, 2, 2]               0\n",
      "================================================================\n",
      "Total params: 46,554\n",
      "Trainable params: 46,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.62\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 298
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:39:58.701318Z",
     "start_time": "2024-06-19T02:39:58.694198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(model_2.parameters(), lr = 0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "id": "9611afe91e37c263",
   "outputs": [],
   "execution_count": 299
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:46:09.791310Z",
     "start_time": "2024-06-19T02:39:58.703902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_accuracy = train_step(model=model_2, data_loader=train_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, optimizer=optimizer, device=device)\n",
    "    \n",
    "    val_loss, val_accuracy = val_step(data_loader=val_dataloader, model=model_2, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Save the model if it has the best validation loss so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model_0.state_dict(), 'best_model_fcn1.pth')\n",
    "\n"
   ],
   "id": "23bc084d3b2cf18",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:37<05:37, 37.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.3150, Train Accuracy: 27.16%, Val Loss: 1.4077, Val Accuracy: 54.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [01:14<04:58, 37.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.6916, Train Accuracy: 79.08%, Val Loss: 0.3881, Val Accuracy: 88.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [01:51<04:20, 37.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.3137, Train Accuracy: 90.78%, Val Loss: 0.2502, Val Accuracy: 92.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [02:28<03:42, 37.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.2263, Train Accuracy: 93.22%, Val Loss: 0.1919, Val Accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [03:05<03:05, 37.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.1868, Train Accuracy: 94.38%, Val Loss: 0.1657, Val Accuracy: 95.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [03:42<02:28, 37.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.1633, Train Accuracy: 95.01%, Val Loss: 0.1490, Val Accuracy: 95.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [04:19<01:51, 37.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.1454, Train Accuracy: 95.65%, Val Loss: 0.1477, Val Accuracy: 95.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [04:56<01:14, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.1323, Train Accuracy: 96.04%, Val Loss: 0.1354, Val Accuracy: 95.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [05:33<00:37, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.1226, Train Accuracy: 96.32%, Val Loss: 0.1204, Val Accuracy: 96.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [06:11<00:00, 37.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.1141, Train Accuracy: 96.67%, Val Loss: 0.1259, Val Accuracy: 96.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 300
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:46:16.682776Z",
     "start_time": "2024-06-19T02:46:09.793218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# for testing \n",
    "# Load the best model for testing\n",
    "model_0.load_state_dict(torch.load('best_model_fcn1.pth'))\n",
    "test_loss, test_accuracy = test_step(data_loader=test_dataloader, model=model_2, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "id": "300e7aaec1e86794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1085, Test Accuracy: 96.40%\n"
     ]
    }
   ],
   "execution_count": 301
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## K - Fold CrossValidation - ",
   "id": "dfd2d6568a4510ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T02:46:16.692988Z",
     "start_time": "2024-06-19T02:46:16.684804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "num_epochs = 5\n"
   ],
   "id": "ae345199329c3a0",
   "outputs": [],
   "execution_count": 302
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:28:48.951385Z",
     "start_time": "2024-06-19T02:46:16.695173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define empty lists to store losses and accuracies\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "\n",
    "# Training loop for k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_val_data)):\n",
    "    print(f'Fold {fold + 1}/{k_folds}')\n",
    "    \n",
    "    # Initialize model, optimizer, criterion for each fold\n",
    "    model2 = MNISTv2( output_shape=10)\n",
    "    optimizer = torch.optim.SGD(model2.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    fold_training_losses = []\n",
    "    fold_validation_losses = []\n",
    "\n",
    "\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_val_data, batch_size=64, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset=train_val_data, sampler=val_sampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Reset model parameters for each epoch\n",
    "        model2.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss, train_accuracy = train_step(model=model2, data_loader=train_loader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, optimizer=optimizer, device=device)\n",
    "        val_loss, val_accuracy = val_step(data_loader=val_loader, model=model2, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "        \n",
    "        fold_training_losses.append(train_loss)\n",
    "        fold_validation_losses.append(val_loss)\n",
    " \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    training_losses.append(fold_training_losses)\n",
    "    validation_losses.append(fold_validation_losses)\n",
    "\n",
    "\n",
    "print('K-fold cross-validation completed.')\n"
   ],
   "id": "93b362c32ced9aab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/5, Train Loss: 3.3543, Train Accuracy: 13.61%, Val Loss: 3.2385, Val Accuracy: 19.41%\n",
      "Epoch 2/5, Train Loss: 2.3679, Train Accuracy: 30.53%, Val Loss: 1.2908, Val Accuracy: 60.45%\n",
      "Epoch 3/5, Train Loss: 0.7097, Train Accuracy: 77.77%, Val Loss: 0.3618, Val Accuracy: 89.32%\n",
      "Epoch 4/5, Train Loss: 0.3180, Train Accuracy: 90.49%, Val Loss: 0.2891, Val Accuracy: 91.37%\n",
      "Epoch 5/5, Train Loss: 0.2341, Train Accuracy: 92.98%, Val Loss: 0.2249, Val Accuracy: 93.08%\n",
      "Fold 2/5\n",
      "Epoch 1/5, Train Loss: 3.3616, Train Accuracy: 11.26%, Val Loss: 3.2709, Val Accuracy: 14.92%\n",
      "Epoch 2/5, Train Loss: 2.9648, Train Accuracy: 22.68%, Val Loss: 1.4693, Val Accuracy: 55.17%\n",
      "Epoch 3/5, Train Loss: 0.7085, Train Accuracy: 78.48%, Val Loss: 0.3865, Val Accuracy: 88.24%\n",
      "Epoch 4/5, Train Loss: 0.3311, Train Accuracy: 90.36%, Val Loss: 0.2907, Val Accuracy: 91.42%\n",
      "Epoch 5/5, Train Loss: 0.2432, Train Accuracy: 92.90%, Val Loss: 0.2131, Val Accuracy: 93.83%\n",
      "Fold 3/5\n",
      "Epoch 1/5, Train Loss: 3.3861, Train Accuracy: 11.96%, Val Loss: 3.1981, Val Accuracy: 18.26%\n",
      "Epoch 2/5, Train Loss: 1.9585, Train Accuracy: 44.96%, Val Loss: 0.6472, Val Accuracy: 79.86%\n",
      "Epoch 3/5, Train Loss: 0.4594, Train Accuracy: 85.88%, Val Loss: 0.2988, Val Accuracy: 90.83%\n",
      "Epoch 4/5, Train Loss: 0.2658, Train Accuracy: 92.04%, Val Loss: 0.2400, Val Accuracy: 92.77%\n",
      "Epoch 5/5, Train Loss: 0.2046, Train Accuracy: 93.91%, Val Loss: 0.2049, Val Accuracy: 93.92%\n",
      "Fold 4/5\n",
      "Epoch 1/5, Train Loss: 2.9114, Train Accuracy: 17.07%, Val Loss: 2.3957, Val Accuracy: 16.56%\n",
      "Epoch 2/5, Train Loss: 1.4069, Train Accuracy: 54.17%, Val Loss: 0.6491, Val Accuracy: 80.08%\n",
      "Epoch 3/5, Train Loss: 0.4357, Train Accuracy: 86.72%, Val Loss: 0.3691, Val Accuracy: 88.69%\n",
      "Epoch 4/5, Train Loss: 0.2795, Train Accuracy: 91.51%, Val Loss: 0.2531, Val Accuracy: 92.39%\n",
      "Epoch 5/5, Train Loss: 0.2165, Train Accuracy: 93.45%, Val Loss: 0.2173, Val Accuracy: 93.36%\n",
      "Fold 5/5\n",
      "Epoch 1/5, Train Loss: 2.4881, Train Accuracy: 21.90%, Val Loss: 1.8542, Val Accuracy: 38.52%\n",
      "Epoch 2/5, Train Loss: 0.9928, Train Accuracy: 68.76%, Val Loss: 0.4754, Val Accuracy: 86.23%\n",
      "Epoch 3/5, Train Loss: 0.3489, Train Accuracy: 89.67%, Val Loss: 0.2625, Val Accuracy: 92.07%\n",
      "Epoch 4/5, Train Loss: 0.2346, Train Accuracy: 93.02%, Val Loss: 0.2204, Val Accuracy: 93.29%\n",
      "Epoch 5/5, Train Loss: 0.1878, Train Accuracy: 94.37%, Val Loss: 0.1742, Val Accuracy: 94.86%\n",
      "K-fold cross-validation completed.\n"
     ]
    }
   ],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:28:56.178672Z",
     "start_time": "2024-06-19T03:28:48.955811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = test_step(data_loader=test_dataloader, model=model2, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ],
   "id": "83a0961ee7f59f56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1469, Test Accuracy: 95.27%\n"
     ]
    }
   ],
   "execution_count": 304
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:28:56.183195Z",
     "start_time": "2024-06-19T03:28:56.180531Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "364486883aeab4cb",
   "outputs": [],
   "execution_count": 304
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a985043a271daf7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:31:01.171468Z",
     "start_time": "2024-06-19T03:31:01.168723Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a28ed23461ee8d20",
   "outputs": [],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T03:28:56.256280Z",
     "start_time": "2024-06-19T03:28:56.256059Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8db8614b28a2a1ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1327bc59daeb4a88",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
